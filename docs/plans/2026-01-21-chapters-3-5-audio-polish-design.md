# Chapters 3-5 + Audio + Polish Design

## Approach Options (Trade-offs)

**Option A (Recommended):** Modular visualization components per chapter (FilterGate/FilterCascade, ScoringBoard, DeliveryCascade) with shared animation utilities and a central audio engine. Pros: testable, reusable, clear separation between data, visuals, and audio triggers. Cons: more files, more upfront structure work.

**Option B:** Single monolithic Chapter3Scene/Chapter4Scene/Chapter5Scene components that own all layout/animation logic internally. Pros: faster to wire quickly. Cons: hard to test, harder to maintain, animation logic tangled with layout.

**Option C:** Data-driven scene renderer using a JSON-like script describing steps and timelines. Pros: future-proof, easy to reorder steps. Cons: heavy abstraction and time cost now, more fragile for rapid iteration.

**Recommended:** Option A. It aligns with existing component style, keeps tests focused, and makes it easy to surface audio triggers per component.

## Architecture (200-300 words)

Add three new chapter scene components for Chapters 3-5, each composed of smaller visualization units. Chapter 3 will introduce `FilterGate` (single gate with scanline + pass/fail animation), `FilterCascade` (vertical stack of gates with live counters), and `TweetFlowLane` (stream of mini-tweets advancing toward the next gate). Chapter 4 will introduce `ScoringContextTokens` (history chips), `AttentionMap` (highlighted tokens with weights), and `EngagementScoreboard` (13 probability bars + weighted contributions + final score + diversity penalty). Chapter 5 will introduce `TopKSelector` (sorting animation), `VisibilityFilterGate`, and `EngagementCascade` (network expansion + engagement event bursts). Each chapter scene owns its step gating (currentStep) and will expose consistent `data-testid` markers for tests and accessibility. Audio is centralized in a new `audio` module (Tone.js) with a Zustand store for enable/mute and event-level APIs (typewriterKey, filterPass, filterFail, scoreTick, engagementPing, chapterTransition). Visual components trigger audio via small `useEffect` hooks when their animations activate. The App-level scene switch listens to chapter changes and fires the chapter transition sound.

## Data Flow + Animations (200-300 words)

Chapter 3 uses a static set of candidate tweets generated from the existing tweet pool (or a small curated set) and simulates filter pass/fail counts with deterministic pseudo-random slicing so tests remain stable. Each `FilterGate` receives `totalIn`, `totalPass`, and `totalFail` and animates counters using a timed interpolation (progressive update every 120ms). Passing tweets continue down the cascade; failing tweets slide to the side, flash red, and fade. The userâ€™s tweet is rendered with a gold glow chip that persists at the top of every gate. Chapter 4 pulls the real tweet text and audience mix from the config store, uses `predictEngagement` to generate probabilities for the core actions (like/repost/reply/bookmark/click), and derives additional action slots (e.g., report/hide/skip) to reach 13 bars. Weighted scores use the existing `calculateWeightedScore`, and a diversity penalty is applied as a small subtractive overlay. The attention map is a stylized heat band across context tokens with pulsing highlights for the top 3 weights. Chapter 5 sorts a candidate list by score, shows top-K selections with a sweep, then visualizes a simplified delivery network where nodes light up and emit engagement icons. Engagement tally counts animate from predicted probabilities to realized counts.

## Error Handling + Testing (200-300 words)

All chapter components must render safe fallbacks if required data is missing (e.g., empty tweet text uses a placeholder). Async operations (embedding, engagement prediction) are guarded with loading states and basic error logging. For audio, ensure audio initialization is wrapped in user interaction (mute toggle); on unsupported contexts, degrade gracefully with no sound and no crashes. Tests are written before implementation for each new component: verify that gates render labels and counts, candidate streams show pass/fail classes, scoring bars display probabilities and weights, delivery cascade renders top-K entries, and the hover panel in the vector space shows the tweet text. Use deterministic data fixtures so tests do not rely on randomness. Also add tests for audio store defaults (mobile muted by default) and for reduced-motion and high-contrast data attributes on the app shell. Once new components exist, update App to render chapters 3-5 and keep the existing Timeline/FunctionPanel integration intact. Finish with a focused App smoke test to ensure the new scenes render without the prior "coming soon" placeholder.
